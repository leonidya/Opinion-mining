{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2419b081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:21:42.930120Z",
     "start_time": "2023-01-19T10:21:42.912117Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------- NLTK: pretrained \"SentimentIntensityAnalyzer\"-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f02bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:22:21.950995Z",
     "start_time": "2023-01-19T10:22:21.888142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the Sentiment140 dataset as a data frame\n",
    "# Print the first 5 rows of the data frame\n",
    "use_cols = ['airline_sentiment','airline_sentiment_confidence','negativereason','negativereason_confidence','airline','airline_sentiment_gold','name','negativereason_gold','retweet_count','text']\n",
    "data = pd.read_csv('tweets.csv', index_col=None, usecols=use_cols)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ffe4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:23:07.293134Z",
     "start_time": "2023-01-19T10:23:07.279148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"airline_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fbf51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:23:29.701390Z",
     "start_time": "2023-01-19T10:23:29.695389Z"
    }
   },
   "source": [
    "Now lets start to work with NLTK and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3963c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:23:49.779759Z",
     "start_time": "2023-01-19T10:23:48.223452Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk # make sure to download the lexicone\n",
    "nltk.downloader.download('vader_lexicon', quiet=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3484f2d",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de14294c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:25:18.866322Z",
     "start_time": "2023-01-19T10:25:18.831194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sentiment_intensity_analyzer = SentimentIntensityAnalyzer()\n",
    "print(sentiment_intensity_analyzer.polarity_scores('I love my smartphone'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa056d",
   "metadata": {},
   "source": [
    "compound: a normalized score between -1 and 1, which indicates the overall sentiment of the text.\n",
    "\n",
    "pos, neg, neu: the positive, negative and neutral sentiment scores respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4b6f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:26:14.572026Z",
     "start_time": "2023-01-19T10:26:14.559003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.471, 'pos': 0.529, 'compound': 0.6696}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_intensity_analyzer.polarity_scores('I love my smartphone very much!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a934c333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:26:17.220123Z",
     "start_time": "2023-01-19T10:26:17.214121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5859}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_intensity_analyzer.polarity_scores('Fraud'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc18c707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:26:17.993932Z",
     "start_time": "2023-01-19T10:26:17.983805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.412, 'pos': 0.588, 'compound': 0.6908}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_intensity_analyzer.polarity_scores(\"It's too good to be true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d428e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:26:19.793437Z",
     "start_time": "2023-01-19T10:26:19.776334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.303, 'neu': 0.697, 'pos': 0.0, 'compound': -0.75}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_intensity_analyzer.polarity_scores(\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c279f9",
   "metadata": {},
   "source": [
    "A positive compound score indicates a positive overall sentiment, a negative compound score indicates a negative overall sentiment, and a score of 0 indicates a neutral overall sentiment. Now let's chek it on our data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49831d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:27:05.413179Z",
     "start_time": "2023-01-19T10:27:05.408178Z"
    }
   },
   "source": [
    "Now let's check the model on our results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf3f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:29:44.461289Z",
     "start_time": "2023-01-19T10:29:44.447649Z"
    }
   },
   "source": [
    "But the question is, how we can summarize this dictionary, for example: {'neg': 0.303, 'neu': 0.697, 'pos': 0.0, 'compound': -0.75} in order to have one answer? I want the result will be Negative, Positive or Neutral and not a dictionary. Let's try it with thresold of 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c84b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:32:43.339633Z",
     "start_time": "2023-01-19T10:32:43.326611Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_sentiment(scores):\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b54b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:33:05.232101Z",
     "start_time": "2023-01-19T10:33:05.215021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_intensity_analyzer.polarity_scores(\"I love this product!\")\n",
    "print(summarize_sentiment(scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d781b",
   "metadata": {},
   "source": [
    "Let's implement that model on our texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b443ddcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:35:01.208167Z",
     "start_time": "2023-01-19T10:34:52.974381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 14640\n",
       "unique                                                 8122\n",
       "top       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "freq                                                   3223\n",
       "Name: scores_NLTK, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sentiment score for each review\n",
    "data['scores_NLTK'] = data['text'].apply(lambda x: sentiment_intensity_analyzer.polarity_scores(x))\n",
    "data['scores_NLTK'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a3ae06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:36:09.849064Z",
     "start_time": "2023-01-19T10:36:09.822788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>scores_NLTK</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>{'neg': 0.246, 'neu': 0.754, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>{'neg': 0.321, 'neu': 0.679, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>{'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.723, 'pos': 0.277, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.952, 'pos': 0.048, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  airline_sentiment_confidence          negativereason  \\\n",
       "0               neutral                        1.0000                     NaN   \n",
       "1              positive                        0.3486                     NaN   \n",
       "2               neutral                        0.6837                     NaN   \n",
       "3              negative                        1.0000              Bad Flight   \n",
       "4              negative                        1.0000              Can't Tell   \n",
       "...                 ...                           ...                     ...   \n",
       "14635          positive                        0.3487                     NaN   \n",
       "14636          negative                        1.0000  Customer Service Issue   \n",
       "14637           neutral                        1.0000                     NaN   \n",
       "14638          negative                        1.0000  Customer Service Issue   \n",
       "14639           neutral                        0.6771                     NaN   \n",
       "\n",
       "       negativereason_confidence         airline airline_sentiment_gold  \\\n",
       "0                            NaN  Virgin America                    NaN   \n",
       "1                         0.0000  Virgin America                    NaN   \n",
       "2                            NaN  Virgin America                    NaN   \n",
       "3                         0.7033  Virgin America                    NaN   \n",
       "4                         1.0000  Virgin America                    NaN   \n",
       "...                          ...             ...                    ...   \n",
       "14635                     0.0000        American                    NaN   \n",
       "14636                     1.0000        American                    NaN   \n",
       "14637                        NaN        American                    NaN   \n",
       "14638                     0.6659        American                    NaN   \n",
       "14639                     0.0000        American                    NaN   \n",
       "\n",
       "                  name negativereason_gold  retweet_count  \\\n",
       "0              cairdin                 NaN              0   \n",
       "1             jnardino                 NaN              0   \n",
       "2           yvonnalynn                 NaN              0   \n",
       "3             jnardino                 NaN              0   \n",
       "4             jnardino                 NaN              0   \n",
       "...                ...                 ...            ...   \n",
       "14635  KristenReenders                 NaN              0   \n",
       "14636         itsropes                 NaN              0   \n",
       "14637         sanyabun                 NaN              0   \n",
       "14638       SraJackson                 NaN              0   \n",
       "14639        daviddtwu                 NaN              0   \n",
       "\n",
       "                                                    text  \\\n",
       "0                    @VirginAmerica What @dhepburn said.   \n",
       "1      @VirginAmerica plus you've added commercials t...   \n",
       "2      @VirginAmerica I didn't today... Must mean I n...   \n",
       "3      @VirginAmerica it's really aggressive to blast...   \n",
       "4      @VirginAmerica and it's a really big bad thing...   \n",
       "...                                                  ...   \n",
       "14635  @AmericanAir thank you we got on a different f...   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637  @AmericanAir Please bring American Airlines to...   \n",
       "14638  @AmericanAir you have my money, you change my ...   \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                                             scores_NLTK   summary  \n",
       "0      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "1      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "2      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "3      {'neg': 0.246, 'neu': 0.754, 'pos': 0.0, 'comp...  Negative  \n",
       "4      {'neg': 0.321, 'neu': 0.679, 'pos': 0.0, 'comp...  Negative  \n",
       "...                                                  ...       ...  \n",
       "14635  {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...  Positive  \n",
       "14636  {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'comp...  Negative  \n",
       "14637  {'neg': 0.0, 'neu': 0.723, 'pos': 0.277, 'comp...  Positive  \n",
       "14638  {'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'comp...  Positive  \n",
       "14639  {'neg': 0.0, 'neu': 0.952, 'pos': 0.048, 'comp...  Positive  \n",
       "\n",
       "[14640 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'] = data['scores_NLTK'].apply(lambda x: summarize_sentiment(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e85ec",
   "metadata": {},
   "source": [
    "Let's check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c17014c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:52:02.621103Z",
     "start_time": "2023-01-19T10:52:02.205091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision(micro): 0.542827868852459\n",
      "Precision(macro): 0.5397306221951211\n",
      "Precision(weighted): 0.6985683472029285\n",
      "Recall: 0.542827868852459\n",
      "F1 score: 0.5653261711946944\n",
      "Confusion Matrix [[4563 1905 2710]\n",
      " [ 431 1325 1343]\n",
      " [  89  215 2059]]\n"
     ]
    }
   ],
   "source": [
    "import nbformat.v4 as nbformat\n",
    "from sklearn import metrics\n",
    "# Compute the precision, recall, and F1 score\n",
    "labels_test=data[\"airline_sentiment\"]\n",
    "data['summary'] = data['summary'].apply(lambda x: x.lower())\n",
    "predictions=data['summary']\n",
    "\n",
    "precision_micro = metrics.precision_score(labels_test, predictions, average=\"micro\")\n",
    "precision_macro = metrics.precision_score(labels_test, predictions, average=\"macro\")\n",
    "precision_weighted = metrics.precision_score(labels_test, predictions, average=\"weighted\")\n",
    "recall = metrics.recall_score(labels_test, predictions,average=\"weighted\")\n",
    "f1 = metrics.f1_score(labels_test, predictions, average=\"weighted\")\n",
    "# auc=metrics.roc_auc_score(labels_test, predictions)\n",
    "cm = metrics.confusion_matrix(labels_test,predictions)\n",
    "# # Print the results\n",
    "print('Precision(micro):', precision_micro)\n",
    "# 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "print('Precision(macro):', precision_macro)\n",
    "# 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "print('Precision(weighted):', precision_weighted)\n",
    "\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)\n",
    "# print('AUC score:', auc)\n",
    "print('Confusion Matrix', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdce8efb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T10:56:40.357117Z",
     "start_time": "2023-01-19T10:56:40.348529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"airline_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c47c972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:07:25.470209Z",
     "start_time": "2023-01-19T11:07:25.451105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    6112\n",
       "negative    5083\n",
       "neutral     3445\n",
       "Name: summary, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"summary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "392d0b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:03:27.063477Z",
     "start_time": "2023-01-19T11:03:27.054730Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "df_cm = pd.DataFrame(cm, index = class_names, columns = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f6aceb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:03:28.249177Z",
     "start_time": "2023-01-19T11:03:28.236175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>4563</td>\n",
       "      <td>1905</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>431</td>\n",
       "      <td>1325</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>89</td>\n",
       "      <td>215</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Neutral  Positive\n",
       "Negative      4563     1905      2710\n",
       "Neutral        431     1325      1343\n",
       "Positive        89      215      2059"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9a4da",
   "metadata": {},
   "source": [
    "NLTK: pretrained \"SentimentIntensityAnalyzer\" made multiple mistakes. In my opinion it happen becouse of the threshold I need to choose. At the end what we can do is to low the threshold for negative or positive, or combine positive and negative with neutral score ( and there is a lot of other options). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318ce06",
   "metadata": {},
   "source": [
    "Change the threshold to 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c063986a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:15:37.995418Z",
     "start_time": "2023-01-19T11:15:37.979623Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_sentiment(scores):\n",
    "    if scores['compound'] >= 0.2:\n",
    "        return \"Positive\"\n",
    "    elif scores['compound'] <= -0.2:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e449671a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:15:38.451917Z",
     "start_time": "2023-01-19T11:15:38.442893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_intensity_analyzer.polarity_scores(\"I love this product!\")\n",
    "print(summarize_sentiment(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83f77f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:15:47.144811Z",
     "start_time": "2023-01-19T11:15:38.875054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 14640\n",
       "unique                                                 8122\n",
       "top       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "freq                                                   3223\n",
       "Name: scores_NLTK, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sentiment score for each review\n",
    "data['scores_NLTK'] = data['text'].apply(lambda x: sentiment_intensity_analyzer.polarity_scores(x))\n",
    "data['scores_NLTK'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6a3e928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:15:47.176938Z",
     "start_time": "2023-01-19T11:15:47.147180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>scores_NLTK</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>{'neg': 0.246, 'neu': 0.754, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>{'neg': 0.321, 'neu': 0.679, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>{'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.723, 'pos': 0.277, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.952, 'pos': 0.048, 'comp...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  airline_sentiment_confidence          negativereason  \\\n",
       "0               neutral                        1.0000                     NaN   \n",
       "1              positive                        0.3486                     NaN   \n",
       "2               neutral                        0.6837                     NaN   \n",
       "3              negative                        1.0000              Bad Flight   \n",
       "4              negative                        1.0000              Can't Tell   \n",
       "...                 ...                           ...                     ...   \n",
       "14635          positive                        0.3487                     NaN   \n",
       "14636          negative                        1.0000  Customer Service Issue   \n",
       "14637           neutral                        1.0000                     NaN   \n",
       "14638          negative                        1.0000  Customer Service Issue   \n",
       "14639           neutral                        0.6771                     NaN   \n",
       "\n",
       "       negativereason_confidence         airline airline_sentiment_gold  \\\n",
       "0                            NaN  Virgin America                    NaN   \n",
       "1                         0.0000  Virgin America                    NaN   \n",
       "2                            NaN  Virgin America                    NaN   \n",
       "3                         0.7033  Virgin America                    NaN   \n",
       "4                         1.0000  Virgin America                    NaN   \n",
       "...                          ...             ...                    ...   \n",
       "14635                     0.0000        American                    NaN   \n",
       "14636                     1.0000        American                    NaN   \n",
       "14637                        NaN        American                    NaN   \n",
       "14638                     0.6659        American                    NaN   \n",
       "14639                     0.0000        American                    NaN   \n",
       "\n",
       "                  name negativereason_gold  retweet_count  \\\n",
       "0              cairdin                 NaN              0   \n",
       "1             jnardino                 NaN              0   \n",
       "2           yvonnalynn                 NaN              0   \n",
       "3             jnardino                 NaN              0   \n",
       "4             jnardino                 NaN              0   \n",
       "...                ...                 ...            ...   \n",
       "14635  KristenReenders                 NaN              0   \n",
       "14636         itsropes                 NaN              0   \n",
       "14637         sanyabun                 NaN              0   \n",
       "14638       SraJackson                 NaN              0   \n",
       "14639        daviddtwu                 NaN              0   \n",
       "\n",
       "                                                    text  \\\n",
       "0                    @VirginAmerica What @dhepburn said.   \n",
       "1      @VirginAmerica plus you've added commercials t...   \n",
       "2      @VirginAmerica I didn't today... Must mean I n...   \n",
       "3      @VirginAmerica it's really aggressive to blast...   \n",
       "4      @VirginAmerica and it's a really big bad thing...   \n",
       "...                                                  ...   \n",
       "14635  @AmericanAir thank you we got on a different f...   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637  @AmericanAir Please bring American Airlines to...   \n",
       "14638  @AmericanAir you have my money, you change my ...   \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                                             scores_NLTK   summary  \n",
       "0      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "1      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "2      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "3      {'neg': 0.246, 'neu': 0.754, 'pos': 0.0, 'comp...  Negative  \n",
       "4      {'neg': 0.321, 'neu': 0.679, 'pos': 0.0, 'comp...  Negative  \n",
       "...                                                  ...       ...  \n",
       "14635  {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...  Positive  \n",
       "14636  {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'comp...  Negative  \n",
       "14637  {'neg': 0.0, 'neu': 0.723, 'pos': 0.277, 'comp...  Positive  \n",
       "14638  {'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'comp...  Positive  \n",
       "14639  {'neg': 0.0, 'neu': 0.952, 'pos': 0.048, 'comp...   Neutral  \n",
       "\n",
       "[14640 rows x 12 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'] = data['scores_NLTK'].apply(lambda x: summarize_sentiment(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca873517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:15:47.587554Z",
     "start_time": "2023-01-19T11:15:47.178837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision(micro): 0.5298497267759563\n",
      "Precision(macro): 0.5407337365543334\n",
      "Precision(weighted): 0.7030271542285867\n",
      "Recall: 0.5298497267759563\n",
      "F1 score: 0.549293588567855\n",
      "Confusion Matrix [[4162 2806 2210]\n",
      " [ 335 1562 1202]\n",
      " [  70  260 2033]]\n"
     ]
    }
   ],
   "source": [
    "import nbformat.v4 as nbformat\n",
    "from sklearn import metrics\n",
    "# Compute the precision, recall, and F1 score\n",
    "labels_test=data[\"airline_sentiment\"]\n",
    "data['summary'] = data['summary'].apply(lambda x: x.lower())\n",
    "predictions=data['summary']\n",
    "\n",
    "precision_micro = metrics.precision_score(labels_test, predictions, average=\"micro\")\n",
    "precision_macro = metrics.precision_score(labels_test, predictions, average=\"macro\")\n",
    "precision_weighted = metrics.precision_score(labels_test, predictions, average=\"weighted\")\n",
    "recall = metrics.recall_score(labels_test, predictions,average=\"weighted\")\n",
    "f1 = metrics.f1_score(labels_test, predictions, average=\"weighted\")\n",
    "# auc=metrics.roc_auc_score(labels_test, predictions)\n",
    "cm = metrics.confusion_matrix(labels_test,predictions)\n",
    "# # Print the results\n",
    "print('Precision(micro):', precision_micro)\n",
    "# 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "print('Precision(macro):', precision_macro)\n",
    "# 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "print('Precision(weighted):', precision_weighted)\n",
    "\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)\n",
    "# print('AUC score:', auc)\n",
    "print('Confusion Matrix', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc0080c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T11:15:47.602404Z",
     "start_time": "2023-01-19T11:15:47.589554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>4162</td>\n",
       "      <td>2806</td>\n",
       "      <td>2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>335</td>\n",
       "      <td>1562</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>70</td>\n",
       "      <td>260</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Neutral  Positive\n",
       "Negative      4162     2806      2210\n",
       "Neutral        335     1562      1202\n",
       "Positive        70      260      2033"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "df_cm = pd.DataFrame(cm, index = class_names, columns = class_names)\n",
    "df_cm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96da7e",
   "metadata": {},
   "source": [
    "Short Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e50508",
   "metadata": {},
   "source": [
    "It looks like it improved the precision but lowered the recall. It appears that the natural language processing (NLP) library NLTK is not accurately recognizing the sentiment of the text in the file.The main reason is not the model it's self, but the difficulty to make a decision. Now, we not always want to make specific desicion, for example in finance, when we want to make a sentiment analysis of the questions of analyst ask in earning calls. Maybe here we would like to have those 3 values in front of us, and then make a decision (hold, sell or buy). So this model will suit us well. But specifically in this project i want to recognize the sentiment of the text, where it will make a decision automatically - if it's positive, negative or neutral. Maybe because of the laziness, or maybe because this model doesn't fit, I would prefer to move to examine another models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
